

----------------------------------------------------------------------------------------------------------------
1. Java Installation : 

[centos@ip-172-31-86-192 ~]$sudo yum install java-1.8.0-openjdk-devel
[centos@ip-172-31-86-192 ~]$java -version
	openjdk version "1.8.0_312"
	OpenJDK Runtime Environment (build 1.8.0_312-b07)
	OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)

[centos@ip-172-31-86-192 ~]$ readlink -f $(which java)
	/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.362.b08-1.el7_9.x86_64/jre/bin/java

[centos@ip-172-31-86-192 ~]$sudo vi /etc/profile
(Add below 2 lines at end)
	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.362.b08-1.el7_9.x86_64/jre
	export PATH=$JAVA_HOME/bin:$PATH

ctr+x ------> y----> enter  (save and exit) 

$source /etc/profile   (to execute the changes)

$echo $JAVA_HOME

------------------------------------------------------------------------------------------------------------------------
2. Passwordless comminucation 
	ssh-keygen
        cd .ssh/
        cat id_rsa.pub >>authorized_keys
        ssh localhost


-----------------------------------------------------------------------------------------------------------------------

3. Download And Extract Hadoop 
wget https://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz
tar -xf hadoop-1.2.1.tar.gz
sudo mv hadoop-1.2.1 /usr/local/hadoop

-------------------------------------------------------------------------------------------------------------------------

4.Update bashrc file 

[centos@ip-172-31-86-192 ~]$ sudo vi .bashrc
(add following at the end of .bashrc file)
	export HADOOP_PREFIX=/usr/local/hadoop/
	export PATH=$PATH:$HADOOP_PREFIX/bin
	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.362.b08-1.el7_9.x86_64/jre 
	export PATH=$PATH:$JAVA_HOME/bin

ctr+x ------> y----> enter  (save and exit)

exec bash  or  bash   (to execute bashrc file)
-----------------------------------------------------------------------------------------------------------------------

5.Update hadoop-env.sh

[centos@ip-172-31-86-192 ~]$cd /usr/local/hadoop/
[centos@ip-172-31-86-192 hadoop]$cd conf/
[centos@ip-172-31-86-192 conf]$sudo vi hadoop-env.sh
(Add following 2 lines)
	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.362.b08-1.el7_9.x86_64/jre 
	export HADOOP_OPTS=-Djava.net.preferIPV4Stack=true

----------------------------------------------------------------------------------------------------------------------

6.Namenode configure 
#core-site.xml
[centos@ip-172-31-86-192 ~]$cd /usr/local/hadoop/
[centos@ip-172-31-86-192 hadoop]$cd conf/
[centos@ip-172-31-86-192 conf]$sudo vi core-site.xml
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>          
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/usr/local/hadoop/tmp</value>
	</property>

#create "tmp" directory
[centos@ip-172-31-86-192 ~]$ mkdir -p /usr/local/hadoop/tmp

------------------------------------------------------------------------------------------------------------------------

7.Configure Datanode
#hdfs-site.xml
[centos@ip-172-31-86-192 ~]$cd /usr/local/hadoop/
[centos@ip-172-31-86-192 hadoop]$cd conf/
[centos@ip-172-31-86-192 conf]$sudo vi hdfs-site.xml
	<configuration>
		<property>
 			<name>dfs.replication</name>
			 <value>1</value>
		</property>
		<property>
			 <name>dfs.permissions</name>
 			<value>false</value>
		</property>
	</configuration>

-----------------------------------------------------------------------------------------------------------------------

8.Configiure Jobtracker/Map-Reduce
#mapred-site.xml
[centos@ip-172-31-86-192 ~]$cd /usr/local/hadoop/
[centos@ip-172-31-86-192 hadoop]$cd conf/
[centos@ip-172-31-86-192 conf]$sudo vi mapred-site.xml
	<property>
		<name>mapred.job.tracker</name>
		<value>hdfs://localhost:9001</value>
	</property>

------------------------------------------------------------------------------------------------------------------

9.exec bash

10.hadoop namenode -format

11.start-dfs.sh

12.start-mapred.sh

#### start-all.sh  (alternate to step 12 & 13)

13.jps

14. hadoop fs -put /local-file-path /hdfs-file-path

15.ls

